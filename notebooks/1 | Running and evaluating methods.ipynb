{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall performance of module detection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,os.path.abspath(\"../lib/\"))\n",
    "\n",
    "import json\n",
    "\n",
    "from util import JSONExtendedEncoder\n",
    "\n",
    "from modulecontainers import Modules\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "import itertools\n",
    "import shutil\n",
    "\n",
    "conf_folder = \"conf/\"\n",
    "\n",
    "import os\n",
    "\n",
    "from modulescomparison import ModevalKnownmodules, ModevalCoverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a method on different parameter settings and datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will explore the parameters of a module detection method on every dataset using a grid-search approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to run your own method, you should wrap it into a python function and add its parameters to `paramexplo_blueprints.py`. We will show the whole workflow here for a \"dummy\"  (but fast) clustering method, which will simply group genes randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every module detection method is wrapped in a python function (see lib/moduledetection.py)\n",
    "\n",
    "Because module detection methods usually take a while to run, we generate the files necessary to run a method on the several parameter settings and datasets here. These can then be easily called from the commandline, for example on a computer cluster or locally using GNU `parallel`.\n",
    "\n",
    "This function will be called by scripts/moduledetection.py , which will save the modules in the correct format along with additional run information (such as running times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets to run\n",
    "#datasetnames = [\"ecoli_colombos\", \"ecoli_dream5\", \"yeast_gpl2529\", \"yeast_dream5\", \"synth_ecoli_regulondb\", \"synth_yeast_macisaac\", \"human_tcga\", \"human_gtex\", \"human_seek_gpl5175\"]\n",
    "datasetnames = [\"human_tcga\"]\n",
    "\n",
    "# paramexplo_blueprints.py stores for every method the parameters which will be varied using a grid-search approach.\n",
    "%run ../conf/paramexplo_blueprints.py\n",
    "\n",
    "# choose the method to evaluate\n",
    "method_name = \"dummy\"\n",
    "methodblueprint = blueprints[method_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate different parameter settings using a grid-search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_folder = \"conf/paramexplo/\" + method_name + \"/\"\n",
    "if os.path.exists(\"../\" + params_folder):\n",
    "    shutil.rmtree(\"../\" + params_folder)\n",
    "os.makedirs(\"../\" + params_folder)\n",
    "\n",
    "methodsettings = []\n",
    "method_locations = []\n",
    "i = 0\n",
    "for dynparam_combination in list(itertools.product(*[methodblueprint[\"dynparams\"][param] for param in sorted(methodblueprint[\"dynparams\"].keys())])):\n",
    "    method = {\"params\":{}}\n",
    "    method[\"params\"] = methodblueprint[\"staticparams\"].copy()\n",
    "    method[\"params\"].update(dict(zip(sorted(methodblueprint[\"dynparams\"].keys()), dynparam_combination)))\n",
    "    method[\"location\"] = params_folder + str(i) + \".json\"\n",
    "    method[\"seed\"] = 0\n",
    "\n",
    "    methodsettings.append(method)\n",
    "\n",
    "    json.dump(method, open(\"../\" + method[\"location\"], \"w\"), cls=JSONExtendedEncoder)\n",
    "\n",
    "    method_locations.append(method[\"location\"])\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now combine the different parameter settings and datasets. Then generate the different python commands to run every parameter setting and dataset in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_name = \"paramexplo/{method_name}\".format(method_name = method_name)\n",
    "settings = [{\n",
    "        \"dataset_location\":\"conf/datasets/\" + datasetname + \".json\",\n",
    "        \"dataset_name\":datasetname,\n",
    "        \"method_location\":methodsetting[\"location\"],\n",
    "        \"output_folder\":\"results/\" + methodblueprint[\"type\"] + \"/{settings_name}/{i}/\".format(settings_name=settings_name, i=i),\n",
    "        \"settingid\":i\n",
    "    } for i, (datasetname, methodsetting) in enumerate(product(datasetnames, methodsettings))]\n",
    "json.dump(settings, open(\"../conf/settings/{settings_name}.json\".format(settings_name=settings_name), \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dataset = pd.DataFrame([dict(settingid=setting[\"settingid\"], **json.load(open(\"../\" + setting[\"dataset_location\"]))[\"params\"]) for setting in settings])\n",
    "settings_method = pd.DataFrame([dict(settingid=setting[\"settingid\"], **json.load(open(\"../\" + setting[\"method_location\"]))[\"params\"]) for setting in settings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel -a tmp/paramexplo/dummy.txt\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"./\"\n",
    "commands = \"\"\n",
    "for i, setting in enumerate(settings):\n",
    "    #commands += \"python scripts/moduledetection.py {method_location} {dataset_location} {output_folder} 0 test\\n\".format(**setting)\n",
    "    commands += \"python3 scripts/\" + methodblueprint[\"type\"] + \".py {method_location} {dataset_location} {output_folder}\\n\".format(**setting)\n",
    "\n",
    "commands_location = \"tmp/{settings_name}.txt\".format(**locals())\n",
    "os.makedirs(\"../\" + os.path.dirname(commands_location), exist_ok=True)\n",
    "with open(\"../\" + commands_location, \"w\") as outfile:\n",
    "    outfile.write(commands)\n",
    "commands_location = \"tmp/{settings_name}.txt\".format(**locals())\n",
    "os.makedirs(os.path.dirname(base_dir + commands_location), exist_ok=True)\n",
    "with open(base_dir + commands_location, \"w\") as outfile:\n",
    "    outfile.write(commands)\n",
    "    \n",
    "#script_location = generate_batchcode(commands_location, settings_name, len(settings), {\"memory\":\"10G\", \"numcores\":1}, \"biclust_comp2\")\n",
    "\n",
    "# this command can be used on most linux computers to run the different parameter settings in parallel\n",
    "print(\"parallel -a \" + commands_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By comparing with known modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pool of processors\n",
    "if \"pool\" in locals().keys():\n",
    "    pool.close()\n",
    "pool = mp.Pool(mp.cpu_count()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_filtered = [setting for setting in settings if not setting[\"dataset_name\"].startswith(\"human\")] # only evaluate non-human datasets\n",
    "modeval = ModevalKnownmodules(settings_filtered)\n",
    "modeval.run(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeval.save(settings_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the coverage of regulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modulescomparison import ModevalCoverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd_data/thesis/projects/biclust_comp2/code3/moduledetection-evaluation/lib/modulescomparison.py:330: RuntimeWarning: divide by zero encountered in log10\n",
      "  stillenriched = [(np.log10(odds_max) >= cutoff).sum()/len(odds_max) for cutoff in cutoffs]\n",
      "/mnt/hdd_data/thesis/projects/biclust_comp2/code3/moduledetection-evaluation/lib/modulescomparison.py:330: RuntimeWarning: divide by zero encountered in log10\n",
      "  stillenriched = [(np.log10(odds_max) >= cutoff).sum()/len(odds_max) for cutoff in cutoffs]\n",
      "/mnt/hdd_data/thesis/projects/biclust_comp2/code3/moduledetection-evaluation/lib/modulescomparison.py:330: RuntimeWarning: divide by zero encountered in log10\n",
      "  stillenriched = [(np.log10(odds_max) >= cutoff).sum()/len(odds_max) for cutoff in cutoffs]\n",
      "/mnt/hdd_data/thesis/projects/biclust_comp2/code3/moduledetection-evaluation/lib/modulescomparison.py:330: RuntimeWarning: divide by zero encountered in log10\n",
      "  stillenriched = [(np.log10(odds_max) >= cutoff).sum()/len(odds_max) for cutoff in cutoffs]\n",
      "/mnt/hdd_data/thesis/projects/biclust_comp2/code3/moduledetection-evaluation/lib/modulescomparison.py:330: RuntimeWarning: divide by zero encountered in log10\n",
      "  stillenriched = [(np.log10(odds_max) >= cutoff).sum()/len(odds_max) for cutoff in cutoffs]\n"
     ]
    }
   ],
   "source": [
    "# built a pool of processors\n",
    "if \"pool\" in locals().keys():\n",
    "    pool.close()\n",
    "pool = mp.Pool(mp.cpu_count()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating a total of 12 settings.\n"
     ]
    }
   ],
   "source": [
    "settings_filtered = [setting for setting in settings if setting[\"dataset_name\"].startswith(\"human\")] # only evaluate human datasets\n",
    "modeval = ModevalCoverage(settings_filtered)\n",
    "modeval.run(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeval.save(settings_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeval.load(settings_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_method(scores):\n",
    "    methodscores = []\n",
    "    for ((datasetoi, goldstandardoi), scoresoi), ((datasetor, goldstandardor), scoresor) in product(scores.groupby([\"datasetname\", \"goldstandard\"]), scores.groupby([\"datasetname\", \"goldstandard\"])):\n",
    "        if (datasetor.split(\"_\")[0]==\"synth\" and datasetoi.split(\"_\")[0]!=\"synth\") or (datasetor.split(\"_\")[0]!=\"synth\" and datasetoi.split(\"_\")[0]==\"synth\"):\n",
    "            continue\n",
    "                \n",
    "        if (goldstandardoi.split(\"#\")[-1] != goldstandardor.split(\"#\")[-1]):\n",
    "            if (datasetoi.startswith(\"human\") != datasetor.startswith(\"human\")):\n",
    "                \"\"\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # find the most optimal method parameters in the reference dataset (test dataset)\n",
    "        bestparams = scoresor[paramsoi].loc[scoresor[\"score\"].idxmax()]\n",
    "        \n",
    "        try:\n",
    "            rowids = scoresoi.index[np.where(np.all([scoresoi[param] == paramvalue for param, paramvalue in bestparams.items()], 0))[0]]\n",
    "        except:\n",
    "            print(scoresoi)\n",
    "\n",
    "        # now find these parameters in the dataset of interest (training dataset)\n",
    "        rowids = scoresoi.index[np.where(np.all([scoresoi[param] == paramvalue for param, paramvalue in bestparams.items()], 0))[0]]\n",
    "            \n",
    "        if len(rowids) == 0:\n",
    "            print(\"parameters could not be matched!!\", datasetoi, datasetor)\n",
    "            print(bestparams)\n",
    "            print([scoresoi[param] == paramvalue for param, paramvalue in bestparams.items()])\n",
    "        if len(rowids) > 1:\n",
    "            print(datasetoi)\n",
    "            print(\"multiple matched parameters\")\n",
    "            print(scoresoi.loc[rowids][paramsoi])\n",
    "\n",
    "        methodscores.append({\n",
    "            \"datasetoi\":datasetoi,\n",
    "            \"datasetor\":datasetor,\n",
    "            \"score\":scoresoi.loc[rowids,\"score\"].max(),\n",
    "            \"method\":methodname,\n",
    "            \"goldstandardoi\":goldstandardoi,\n",
    "            \"goldstandardor\":goldstandardor,\n",
    "            \"ofinterest\":datasetoi + \"#\" + goldstandardoi,\n",
    "            \"ofreference\":datasetor + \"#\" + goldstandardor,\n",
    "            \"runningtime\":scoresoi.loc[rowids, \"runningtime\"].mean() if \"runningtime\" in scoresoi.columns else 0,\n",
    "            \"moduledef\":scoresoi.loc[rowids, \"moduledef\"].tolist()[0],\n",
    "            \"organismoi\":scoresoi.loc[rowids, \"organism\"].tolist()[0],  \n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(methodscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "methodnames = [\"dummy\", \"agglom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wouters/.local/lib/python3.6/site-packages/pandas/core/frame.py:6201: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agglom\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../results/modeval_coverage/paramexplo/agglom.tsv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-afa9502ac831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodeval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModevalCoverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodeval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mmodeval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodeval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"aucodds_permuted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmodeval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodeval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"settingid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"settingid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hdd_data/thesis/projects/biclust_comp2/code3/moduledetection-evaluation/lib/modulescomparison.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, name, full)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../results/modeval_coverage/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../results/modeval_coverage/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../results/modeval_coverage/paramexplo/agglom.tsv' does not exist"
     ]
    }
   ],
   "source": [
    "finalscores = []\n",
    "for methodname in methodnames:\n",
    "    settings_name = \"paramexplo/\" + methodname\n",
    "    settings = json.load(open(\"../conf/settings/{}.json\".format(settings_name)))\n",
    "    settings_dataset = pd.DataFrame([dict(settingid=settingid, **json.load(open(\"../\" + setting[\"dataset_location\"]))[\"params\"]) for settingid, setting in enumerate(settings)])\n",
    "    settings_method = pd.DataFrame([dict(settingid=settingid, **json.load(open(\"../\" + setting[\"method_location\"]))[\"params\"]) for settingid, setting in enumerate(settings)])\n",
    "    \n",
    "    print(methodname)\n",
    "    paramsoi = methodparamsoi[methodname]\n",
    "\n",
    "    scores = pd.DataFrame()\n",
    "    \n",
    "    modeval = ModevalKnownmodules(settings_name)\n",
    "    modeval.load(settings_name)\n",
    "    modeval.scores[\"score\"] = modeval.scores[\"F1rprr_permuted\"]\n",
    "    modeval.scores[\"moduledef\"] = [modulesname if modulesname in [\"minimal\", \"strict\"] else \"interconnected\" for modulesname in modeval.scores[\"knownmodules_name\"]]\n",
    "    modeval.scores = modeval.scores.merge(settings_dataset, on=\"settingid\").merge(settings_method, on=\"settingid\")\n",
    "    scores = scores.append(modeval.scores, ignore_index=True)\n",
    "    \n",
    "    modeval = ModevalCoverage(settings_name)\n",
    "    modeval.load(settings_name)\n",
    "    modeval.scores[\"score\"] = modeval.scores[\"aucodds_permuted\"]\n",
    "    modeval.scores = modeval.scores.merge(settings_dataset, on=\"settingid\").merge(settings_method, on=\"settingid\")\n",
    "    scores = scores.append(modeval.scores, ignore_index=True)\n",
    "    \n",
    "    methodscores = score_method(scores)\n",
    "    \n",
    "    methodscores[\"organismnetoi\"] = [dataset.split(\"_\")[0] for dataset in methodscores[\"goldstandardoi\"]]\n",
    "    methodscores[\"organismnetor\"] = [dataset.split(\"_\")[0] for dataset in methodscores[\"goldstandardor\"]]\n",
    "\n",
    "    finalscores.append(methodscores)\n",
    "finalscores = pd.concat(finalscores, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weights(scores):\n",
    "    weights = []\n",
    "    scores[\"moduledef\"] = scores[\"moduledef\"].fillna(\"\")\n",
    "    for organismoi, subscores in scores.groupby(\"organismoi\"):\n",
    "        moduledef_weights = 1/subscores.groupby(\"moduledef\")[\"score\"].count()\n",
    "        for moduledef, weight in moduledef_weights.items():\n",
    "            weights.append({\n",
    "                    \"organism\":organismoi,\n",
    "                    \"moduledef\":moduledef,\n",
    "                    \"weight\":weight / len(moduledef_weights)\n",
    "                })\n",
    "    weights = pd.DataFrame(weights).set_index([\"organism\", \"moduledef\"])[\"weight\"]\n",
    "    \n",
    "    scores[\"weight\"] = weights.loc[pd.Index(scores[[\"organismoi\", \"moduledef\"]])].tolist()\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "trainingscores_ = add_weights(finalscores.loc[(finalscores[\"ofinterest\"] == finalscores[\"ofreference\"])])\n",
    "testscores_ = add_weights(finalscores.loc[(finalscores[\"ofinterest\"] != finalscores[\"ofreference\"]) & (finalscores[\"organismnetoi\"] != finalscores[\"organismnetor\"])])\n",
    "\n",
    "trainingscores = trainingscores_.groupby(\"method\").apply(lambda x: np.average(x.score, weights=x.weight))\n",
    "testscores = testscores_.groupby(\"method\").apply(lambda x: np.average(x.score, weights=x.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "testscores_.to_csv(\"../results/testscores_.tsv\", sep=\"\\t\")\n",
    "trainingscores_.to_csv(\"../results/trainingscores_.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method\n",
       "dummy    0.68831\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 36x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = subplots(figsize=(len(trainingscores)/2, 5))\n",
    "\n",
    "methodorder = testscores.sort_values(ascending=False).index\n",
    "\n",
    "ax.bar(range(len(methodorder)), trainingscores[methodorder], color=\"grey\")\n",
    "ax.bar(range(len(methodorder)), testscores[methodorder], color=\"#333333\")\n",
    "ax.set_xlim(-0.2, len(methodorder))\n",
    "ax.set_xticks(np.arange(len(methodorder))+0.4)\n",
    "ax.set_xticklabels(methodorder, rotation=45, ha=\"right\", va=\"top\")\n",
    "\"\"\n",
    "\n",
    "\n",
    "ax.tick_params(labelsize=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
